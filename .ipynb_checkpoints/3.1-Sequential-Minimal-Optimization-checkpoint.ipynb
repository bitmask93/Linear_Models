{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrange Duality\n",
    "\n",
    "\n",
    "- Consider the following Primal Optimization Problem :\n",
    "\n",
    "$$\\underset{w}{min}\\;f(w)$$\n",
    "$$s.t$$\n",
    "$$g_{i}(w)\\leq0, i=1,....,k$$\n",
    "$$h_{i}(w)=0, i=1,....,l$$\n",
    "\n",
    "- To solve this, let us define the Lagrangian as :\n",
    "\n",
    "$$L\\left ( w,\\alpha,\\beta \\right ) = f(w)+\\sum_{i=1}^{k}\\alpha_{i}g_{i}(w) + \\sum_{i=1}^{l}\\beta_{i}h_{i}(w)$$\n",
    "\n",
    "- Here the $\\alpha_{i}$'s and $\\beta_{i}$'s are the Lagrange Multipliers.\n",
    "\n",
    "\n",
    "- Now let us define the primal Lagrangian function as. : \n",
    "\n",
    "$$p(w) = \\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}L(w,\\alpha,\\beta)$$\n",
    "\n",
    "\n",
    "- For any given $w$, if $w$ violates any of the Primal constraints, then it can be shown that : \n",
    "\n",
    "$$p(w) = \\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}f(w) + \\sum_{i=1}^{k}\\alpha_{i}g_{i}(w)+ \\sum_{i=1}^{l}\\beta_{i}h_{i}(w) = \\infty$$\n",
    "\n",
    "- Now if the constraints are satisfied for a particular value of $w$, then $p(w) = f(w)$.\n",
    "\n",
    "\n",
    "- This can be given as follows : \n",
    "\n",
    "$$p(w) = \\left\\{\\begin{matrix}\n",
    "f(w) & if\\;w\\;satisfies\\;primal\\;constraints \\\\ \n",
    "\\infty & Otherwise \n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "\n",
    "- Now if we consider the minimization problem :\n",
    "\n",
    "$$\\underset{w}{min}\\;p(w) =  \\underset{w}{min}\\;\\;\\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}L(w,\\alpha,\\beta)$$\n",
    "\n",
    "- We have already seen that $p(w)$ takes the same value as the objective for all values of $w$ that satisfies the primal constraints and $\\infty$ otherwise. So we can clearly see from the minimization problem that the solutions of this problem is same as the original Primal Problem. Now let us define the optimal value of the objective to be :\n",
    "$$p^{*} =  \\underset{w}{min}\\;p(w)$$\n",
    "\n",
    "\n",
    "- Now let us define the Dual Lagrangian function as :\n",
    "\n",
    "$$d(\\alpha,\\beta) = \\underset{w}{min}\\;L(w,\\alpha,\\beta)$$\n",
    "\n",
    "- Now we can pose the Dual Optimization problem as :\n",
    "\n",
    "$$\\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}\\;d(\\alpha,\\beta) = \\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}\\;\\underset{w}{min}\\;L(w,\\alpha,\\beta)$$\n",
    "\n",
    "- Now let's define the optimal value of the dual problem objective as : \n",
    "\n",
    "$$d^{*} = \\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}\\;g(\\alpha,\\beta)$$\n",
    "\n",
    "\n",
    "- Now it can be shown that :\n",
    "\n",
    "$$d^{*} = \\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}\\underset{w}{min}\\;L(w,\\alpha,\\beta)\\leq \\underset{w}{min}\\;\\underset{\\alpha,\\beta:\\alpha_{i}\\geq0}{max}L(w,\\alpha,\\beta) = p^{*}$$\n",
    "\n",
    "\n",
    "- \"Max-min\" of a function will always be less than or equal to \"Min-max\". Also under certain conditions, $d^{*} = p^{*}$. These conditions are :\n",
    "\n",
    "    - > Suppose $f$ and $g_{i}$'s are convex and $h_{i}$'s are Affine, and the constraints $g_{i}$ are strictly feasible; this means there exists some $w$, so that $g_{i}(w)<i$ for all $i$.  \n",
    "\n",
    "- This means that we can solve the dual problem instead of the primal problem. So there must exist $w^{*}$, $\\alpha^{*}$, $\\beta^{*}$ so that $w^{*}$ is the solution to the primal and $\\alpha^{*}$ and $\\beta^{*}$ are the solutions to the Dual Problem and $p^{*} = d^{*}$.\n",
    "\n",
    "\n",
    "- Here $w^{*}$, $\\alpha^{*}$, $\\beta^{*}$ satisfy the Karush-Kuhn-Tucker(KKT) constraints which are as follows : \n",
    "\n",
    "$$\\frac{\\delta  }{\\delta w_{i} }L(w^{*},\\alpha^{*},\\beta^{*}) = 0, i=1,....,n$$\n",
    "\n",
    "$$\\frac{\\delta  }{\\delta \\beta_{i} }L(w^{*},\\alpha^{*},\\beta^{*}) = 0, i=1,....,l$$\n",
    "\n",
    "$$\\alpha_{i}^{*}g_{i}(w^{*}) = 0, i=1,....,k$$\n",
    "\n",
    "$$g_{i}(w^{*})\\leq0, i=1,.....,k$$\n",
    "\n",
    "$$h_{i}(w^{*})=0, i=1,.....,l$$\n",
    "\n",
    "$$\\alpha^{*}\\geq 0, i=1,.....,k$$\n",
    "\n",
    "\n",
    "- The first two conditions are called the **Stationarity** conditions.\n",
    "\n",
    "- The third condition is called as **complimentary slackness** condition.\n",
    "\n",
    "- The fourth and fifth conditions are called as **primal feasibility** condition.\n",
    "\n",
    "- The final condition is called as **Dual feasibility** condition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Margin Classifiers : \n",
    "\n",
    "\n",
    "- The Primal Optimization problem for an Optimal margin Classifer is given as :\n",
    "\n",
    "$$\\underset{w,b}{min}\\frac{1}{2}\\left \\| w \\right \\|^{2}$$\n",
    "$$st.$$\n",
    "\n",
    "$$y_{i}(w^{T}x_{i}+b)\\geq 1, i=1,....,n$$\n",
    "\n",
    "\n",
    "- Now let us construct the Lagrangian for the Optimization problem as :\n",
    "\n",
    "$$L(w,b,\\alpha) = \\frac{1}{2}\\left \\| w \\right \\|^{2} - \\sum_{i=1}^{n}\\alpha_{i}\\left [ y_{i}(w^{T}x_{i}+b)-1 \\right ] $$\n",
    "\n",
    "- To find the dual form of the problem, we need to first minimize $L(w,b,\\alpha)$ wrt. $b$ and $w$, this can be done by setting the derivatives of $L$ wrt. $w$ and $b$ to zero. So we can write this as :\n",
    "\n",
    "$$\\bigtriangledown _{w}L\\left ( w,b,\\alpha \\right ) = w -\\sum_{i=1}^{n}\\alpha_{i}y_{i}x_{i} = 0$$\n",
    "\n",
    "$$\\implies w = \\sum_{i=1}^{n}\\alpha_{i}y_{i}x_{i}$$\n",
    "\n",
    "\n",
    "- For derivatives wrt. $b$, we get :\n",
    "\n",
    "$$\\frac{\\delta }{\\delta b}L(w,b,\\alpha) = \\sum_{i=1}^{n}\\alpha_{i}y_{i} = 0$$\n",
    "\n",
    "\n",
    "- Now we can write the Lagrangian as :\n",
    "\n",
    "$$L(w,b,\\alpha) = \\sum_{i=1}^{n}\\alpha_{i} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}y_{i}y_{j}\\alpha_{i}\\alpha_{j}(x_{i})^{T}x_{j} - b\\sum_{i=1}^{n}\\alpha_{i}y_{i}$$\n",
    "\n",
    "- But we already obtained that the last term of the above equation is zero.\n",
    "\n",
    "\n",
    "- So rewriting the equation, so we get :\n",
    "\n",
    "$$L(w,b,\\alpha) = \\sum_{i=1}^{n}\\alpha_{i} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}y_{i}y_{j}\\alpha_{i}\\alpha_{j}(x_{i})^{T}x_{j}$$\n",
    "\n",
    "\n",
    "- The above equation is obtained by minimizing $L$ wrt. $b$ and $w$. Now putting all this together with all the constraints, we obtain the following : \n",
    "\n",
    "\n",
    "$$\\underset{w}{max}W(\\alpha) = \\sum_{i=1}^{n}\\alpha_{i} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}y_{i}y_{j}\\alpha_{i}\\alpha_{j}\\left \\langle x_{i},x_{j} \\right \\rangle$$\n",
    "\n",
    "$$st.$$\n",
    "\n",
    "$$\\alpha_{i}\\geq 0,\\;i=1,.....,n$$\n",
    "\n",
    "$$\\sum_{i=1}^{n}\\alpha_{i}y_{i} = 0$$\n",
    "\n",
    "\n",
    "- Now once we have found the optimal $\\alpha_{i}$'s we can find optimal $w$$(w^{*})$ using the following :\n",
    "\n",
    "$$w^{*} = \\sum_{i=1}^{n} \\alpha_{i}y_{i}x_{i}$$\n",
    "\n",
    "\n",
    "- Having found $w^{*}$, now we can find the intercept term$(b)$ using the following :\n",
    "\n",
    "$$b = -\\frac{\\underset{i:y_{i}=-1}{max}(w^{*})^{T}x_{i} + \\underset{i:y_{i}=1}{min}(w^{*})^{T}x_{i} }{2}$$\n",
    "\n",
    "\n",
    "- Now once we have fit the model's parameters to the training set, now we need to make the predictions from model, the model will output 1, when $w^{T}x + b$ is strictly greater than 0. We can also express this using the following : \n",
    "\n",
    "$$w^{T}x+b = \\left ( \\sum_{i=1}^{n}\\alpha_{i}y_{i}x_{i} \\right )^{T}x + b$$\n",
    "\n",
    "$$= \\sum_{i=1}^{n}\\alpha_{i}y_{i}\\left \\langle x_{i},x \\right \\rangle + b$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to SMO\n",
    "\n",
    "- Sequential Minimal optimization(SMO) is an iterative algorithm for solving the Quadratic Programming(QP.) problem that arises during the training of Support Vector Machines(SVM). SMO is very fast and can quickly solve the SVM QP without using any QP optimization steps at all.\n",
    "\n",
    "\n",
    "- Consider a binary classification with a dataset $(x_{1},y_{1}),.....,(x_{n},y_{n})$ where $x_{i}$ is the input vector and $y_{i} \\in \\left \\{ -1, + 1 \\right \\}$ which is a binary label corresponding to each $x_{i}$.\n",
    "\n",
    "\n",
    "- A hard-margin SVM is found by solving a QP. problem that is expressed in the dual form as follows : \n",
    "\n",
    "$$max_{\\alpha}\\sum_{i=1}^{n}\\alpha_{i} - \\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=1}^{n}y_{i}y_{j}K(x_{i},x_{j})\\alpha_{i}\\alpha_{j}$$\n",
    "$$subject\\;to$$\n",
    "\n",
    "$$0\\leq \\alpha_{i}\\leq C \\;\\;\\;for\\;\\;i=1,2....,n$$\n",
    "$$\\sum_{i=1}^{n}y_{i}\\alpha_{i} = 0$$\n",
    "\n",
    "\n",
    "- Here $C$ is SVM hyperparameter that controls the tradeoff between maximum margin and loss and $K(x_{i},x_{j})$ is the **Kernel Function**. $\\alpha_{i}$ is **Lagrange Multipliers**.\n",
    "\n",
    "\n",
    "- SMO is an iterative algorithm and in each step it chooses two Lagrange Multipliers to jointly optimize and then finds the optimal values for these multipliers and updates the SVM to reflect the new optimal values.\n",
    "\n",
    "\n",
    "- The main advantage of SMO lies in the fact that solving for two Lagrange multipliers can be done analytically eventhough there are more optimization sub-problems that are being solved, each of these sub-problems can be solved fast and hence the overall QP problem is solved quickly.\n",
    "\n",
    "\n",
    "- The algorithm works like the following :\n",
    "\n",
    "Repeat till convergence\n",
    "\n",
    "{\n",
    "\n",
    "1) Select some pair $\\alpha_{i}$ and $\\alpha_{j}$\n",
    "\n",
    "2) Reoptimize $W(\\alpha)$ wrt. $\\alpha_{i}$ and $\\alpha_{j}$ while holding all other $\\alpha_{k}$'s fixed.\n",
    "\n",
    "}\n",
    "\n",
    "- There are two components to SMO : \n",
    "\n",
    "    - > Analytical Solution for solving for two Lagrange Multipliers\n",
    "    \n",
    "    - > Heuristic for choosing which multipliers to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for two Lagrange Multipliers \n",
    "\n",
    "\n",
    "- SMO first computes the constraints on the two multipliers and then solves for constrained minimum. Since there is a bounding constraints $0\\leq\\alpha_{i}\\leq C$ on the Lagrange multipliers, these Lagrange multipliers will lie within a box.\n",
    "\n",
    "\n",
    "- Also because  $\\sum_{i=1}^{n}y_{i}\\alpha_{i} = 0$ , it causes the Lagrange multipliers to lie on the diagonal. Thus the Constrained minimum of the objective function must lie on a diagonal line segment. This can be seen from the below diagram : \n",
    "\n",
    "<img src=\"images/cons_opt.png\" width=\"600\" height=\"600\">\n",
    "\n",
    "\n",
    "- The inequality constraints cause the Lagrange multipliers to lie in the box. The linear equality constraint causes them to lie on a diagonal line. Therefore, one step of SMO must find an optimum of the objective function on a diagonal line segment.\n",
    "\n",
    "\n",
    "- The algorithm first computes the second Lagrange multiplier $\\alpha_{2}$ and then computes the ends of the diagonal line segment in terms of $\\alpha_{2}$.\n",
    "\n",
    "\n",
    "- If $y_{1}\\neq y_{2}$, then the following bounds apply to $\\alpha_{2}$.\n",
    "\n",
    "$$L = max(0,\\alpha_{2}-\\alpha_{1}), H = min(C,C+\\alpha_{2}-\\alpha_{1})$$\n",
    "\n",
    "\n",
    "- If $y_{1} = y_{2}$, then the following bounds apply to $\\alpha_{2}$\n",
    "\n",
    "$$L = max(0,\\alpha_{2}+\\alpha_{1}-C), H = min(C,\\alpha_{2}-\\alpha_{1})$$\n",
    "\n",
    "\n",
    "- The second derivative of the Objective function along the diagonal is expressed as : \n",
    "\n",
    "$$\\eta = K(x_{1},x_{1}) + K(x_{2},x_{2}) - 2K(x_{1},x_{2})$$\n",
    "\n",
    "\n",
    "- Under normal circumstances, $\\eta$ will be greater than zero and there will be a minimum along the direction of the linear equality constraint. In this case, SMO computes the minimum along the direction of the constraint : \n",
    "\n",
    "$$\\alpha_{2}^{new} = \\alpha_{2} + \\frac{y_{2}(E_{1}-E_{2})}{\\eta}$$\n",
    "\n",
    "\n",
    "- Where $E = \\mu_{i} - y_{i}$, Where $\\mu_{i}$ is the output of the SVM for the $i^{th}$ training example. \n",
    "\n",
    "\n",
    "- The constrained minimum is found by clipping the unconstrained minimum to the ends of the line segment : \n",
    "\n",
    "$$\\alpha_{2}^{clipped} = \\left\\{\\begin{matrix}\n",
    "H & if & \\alpha_{2}^{new}\\geq H \\\\ \n",
    "\\alpha_{2}^{new} & if & L<\\alpha_{2}^{new}<H \\\\ \n",
    "L & if  & \\alpha_{2}^{new}\\leq L \n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "- Let $S = y_{1}y{2}$. The value of $\\alpha_{1}$ is computed from the new clipped $\\alpha_{2}$ : \n",
    "\n",
    "$$\\alpha_{1}^{new} = \\alpha_{1} + S\\left ( \\alpha_{2} - \\alpha_{2}^{clipped} \\right )$$\n",
    "\n",
    "\n",
    "- Under normal circumstances $\\eta > 0$. A negative $\\eta$ occurs if the kernel $K$ does not obey Mercer's Conditions, which states that for any Kernel$(K)$ to be a valid Kernel, it is necessary and sufficient that for any $\\left \\{ x_{1},......,x_{m} \\right \\},\\left ( m<\\infty  \\right )$, the corresponding Kernel Matrix is symmetric positive semi-definite.\n",
    "\n",
    "\n",
    "- $\\eta = 0$ when more than one training example has the same input vector $x$.\n",
    "\n",
    "\n",
    "- SMO will work even when $\\eta$ is not positive, in which casae the objective function$(\\psi )$ should be evaluated at each end of the line segment.\n",
    "\n",
    "\n",
    "$$ f_{1} = y_{1}\\left ( E_{1} + b \\right ) - \\alpha_{1}K\\left ( x_{1},x_{1} \\right ) - S\\alpha_{2}K\\left ( x_{1},x_{2} \\right ) $$\n",
    "\n",
    "\n",
    "$$f_{2} = y_{2}\\left ( E_{2} + b \\right ) - S \\alpha_{1}K(x_{1},x_{2}) - \\alpha_{2} K\\left ( x_{2},x_{2} \\right ) $$\n",
    "\n",
    "\n",
    "$$L_{1} = \\alpha_{1} + S\\left ( \\alpha_{2}-L \\right )$$\n",
    "\n",
    "\n",
    "$$H_{1} = \\alpha_{1} + S\\left ( \\alpha_{2}-H \\right )$$\n",
    "\n",
    "\n",
    "$$\\psi_{L} = L_{1}f_{1} + Lf_{2} + \\frac{1}{2}L_{1}^{2}K\\left ( x_{1},x_{1} \\right ) + \\frac{1}{2}L^{2}K\\left ( x_{2},x_{2} \\right ) + SLL_{1}K\\left ( x_{1},x_{2} \\right )$$\n",
    "\n",
    "\n",
    "$$\\psi_{H} = H_{1}f_{1} + Hf_{2} + \\frac{1}{2}H_{1}^{2}K\\left ( x_{1},x_{1} \\right ) + \\frac{1}{2}H^{2}K\\left ( x_{2},x_{2} \\right ) + SHH_{1}K(x_{1},x_{2})$$.\n",
    "\n",
    "\n",
    "- SMO will move the Lagrange multipliers to the point that has the lowest value of the Objective Function. If Objective function is the same at both ends and Kernel obeys Mercer's conditions, then the joint minimization cannot make progress, in such situations we use the Heuristic approach, which is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic for choosing which multipliers to Optimize\n",
    "\n",
    "- According to **Osuna's Theorum**, a large QP. Problem can be broken down into a series of smaller QP sub-problems. A sequence of QP. subproblems that add atleast one violator to the Karush-Kuhn-Tucker(KKT) conditions is guaranteed to converge.\n",
    "\n",
    "\n",
    "- So SMO optimizes and alters two lagrange multipliers at each step and atleast one of the Lagrange multipliers violates the KKT conditions before the next step, then each step will decrease the objective function and thus by the above theorum making sure that convergence does happen.\n",
    "\n",
    "\n",
    "- There are two separate heuristics : one for choosing the first Lagrange multiplier and one for the second.\n",
    "\n",
    "\n",
    "- The coice for the first heuristic forms the outer loop of SMO. The outerloop iterates over the entire training set, and determines if each example violates the KKT conditions and if it does, then it is eligible for optimization.\n",
    "\n",
    "\n",
    "- After one pass through the entire dataset, the outer loop of SMO makes repeated passes over the non-bound examples(examples whose Lagrange Multipliers are neither 0 nor $C$) untill all of the non-bound examples obey the KKT conditions within $\\epsilon$. Typically $\\epsilon$ is chosen to be $10^{-3}$.\n",
    "\n",
    "\n",
    "- As SMO progresses, the examples that are at the bounds are likely to stay at the bounds while the examples that are not at the bounds will move as other examples are optimized. And then finally SMO will scan the entire data set to search for any bound examples that have become KKT violated due to optimizing the non-bound subset.\n",
    "\n",
    "\n",
    "- Once the first Lagrange multiplier is chosen, SMO choses the second Lagrange multiplier to maximize the size of the step taken during the joint optimization. Evaluating the Kernel Function $K$ is time consuming, so SMO appriximates the step size by absolute value of $\\left | E_{1} - E_{2} \\right |$.\n",
    "\n",
    "\n",
    "- If $E_{1}$ is positive, then SMO chooses an example with minimum error $E_{2}$.\n",
    "\n",
    "\n",
    "- If $E_{1}$ is negative, SMO chooses an example with maximum error $E_{2}$.\n",
    "\n",
    "\n",
    "- If two training examples share an identical input vector$(x)$, then a positive progress cannot be made because the objective function becomes semi-definite. In this case, SMO uses a hierarchy of second choice heuristics untill it finds a pair of Lagrange multipliers that can make a positive progress.\n",
    "\n",
    "\n",
    "- The hierarchy of second choice heuristics is as follows :\n",
    "\n",
    "    - > SMO starts iterating through the non-bound examples, searching for a second example that can make a positive progress.\n",
    "    \n",
    "    - > If none of the non-bound examples makes a positive progress, then SMO starts iterating through the entire training set untill an example is found that makes positive progress.\n",
    "    \n",
    "- Both the iteration through the non-bound examples and the iteration through entire training set are started at random locations so as to not bias SMO.\n",
    "\n",
    "\n",
    "- In situations when none of the examples will make an adequete second example, then the first example is skipped and SMO continues with another chosen first example. However this situation is very rare.\n",
    "\n",
    "\n",
    "- The threshold $b$ is re-computed after each step, so that the KKT conditions are fulfilled for both optimized examples.\n",
    "\n",
    "\n",
    "- When the new $\\alpha_{1}$ is not at the bounds, then the output of SVM is forced to be $y_{1}$ when the input is $x_{1}$, hence the following threshold$(b_{1})$ is valid : \n",
    "\n",
    "\n",
    "$$b_{1} = E_{1} + y_{1}\\left ( \\alpha_{1}^{new} - \\alpha_{1}\\right )K\\left ( x_{1},x_{1} \\right ) + y_{2}\\left ( \\alpha_{2}^{clipped} - \\alpha_{2} \\right )K(x_{1},x_{1})+b$$\n",
    "\n",
    "\n",
    "- When the new $\\alpha_{2}$ is not at the bounds, then the output of SVM is forced to be $y_{2}$ when the input is $x_{2}$, hence the following threshold$(b_{2})$ is valid :\n",
    "\n",
    "$$b_{2} = E_{2} + y_{1}\\left ( \\alpha_{1}^{new}-\\alpha_{1} \\right )K(x_{1},x_{2})+y_{2}\\left ( \\alpha_{2}^{clipped} - \\alpha_{2}\\right )K\\left ( x_{2},x_{2} \\right )+b$$\n",
    "\n",
    "\n",
    "- When both $b_{1}$ and $b_{2}$ are valid, they are equal. When both new Lagrange multipliers are bound and $L$ is not equal to $H$, then the interval between $b_{1}$ and $b_{2}$ are all thresholds that are consistent with the KKT conditions. SMO chooses the threshold to be halfway in between $b_{1}$ and $b_{2}$.\n",
    "\n",
    "$$b = \\left\\{\\begin{matrix}\n",
    "b_{1} & if  &0<\\alpha_{i}<C \\\\ \n",
    "b_{2} & if &0<\\alpha_{j}<C \\\\ \n",
    "\\frac{b_{1}+b_{2}}{2} &  & otherwise \n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "\n",
    "- Now to compute Linear SVM, only a single weight vector$(w)$ need to be stored rather than all of the training examples that correspond to non-zero Lagrange multipliers. If the joint optimization succeeds, then the stored weight vector needs to be updated to reflect the new Lagrange multiplier values. The updation step is given by : \n",
    "\n",
    "\n",
    "$$w^{new} = w + y_{1}\\left ( \\alpha_{1}^{new} - \\alpha_{1} \\right )x_{1} + y_{2}\\left ( \\alpha_{2}^{clipped} - \\alpha_{2} \\right )x_{2}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References : \n",
    "\n",
    "- https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Sequential_minimal_optimization\n",
    "\n",
    "- http://pages.cs.wisc.edu/~dpage/cs760/SMOlecture.pdf\n",
    "\n",
    "- http://www.robots.ox.ac.uk/~az/lectures/ml/lect3.pdf\n",
    "\n",
    "- http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/Slides5A.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
